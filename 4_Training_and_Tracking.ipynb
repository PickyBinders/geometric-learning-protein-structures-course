{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --use-pep517 \"graphein[extras]\" lightning torch torch-geometric tensorboard nbformat \"jsonargparse[signatures]\" ipywidgets tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There are a variety of free and paid resources available for interactively tracking training performance of deep learning models. Here we'll use [TensorBoard](https://github.com/tensorflow/tensorboard) which is free and open-source. Another popular option with a free tier is [Weights & Biases](https://wandb.ai/site), which has some additional features and integrations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric import nn as graph_nn\n",
    "from src import dataloader\n",
    "from lightning.pytorch import callbacks\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can actually visualise TensorBoard within the notebook with some cell magic to tell Jupyter to run the server in the background and display it in the notebook, by looking for files in the `lightning_logs` directory. As we run training, log files will be written to this directory by default and the TensorBoard display will update automatically (refreshes every 30 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/ --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's set up the LightningModule again and this time also log the loss value on our validation set. Note that the `validation_step` function automatically runs with gradients disabled, meaning that weights are frozen and the model is in evaluation mode, so we don't need to worry about that. We'll also save the predicted values in an `outputs` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InterfaceModule(lightning.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule wrapping a GAT model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = graph_nn.GAT(in_channels=20,\n",
    "                         hidden_channels=32,\n",
    "                         num_layers=2,\n",
    "                         heads=2,\n",
    "                         out_channels=1,\n",
    "                         dropout=0.01,\n",
    "                         jk=\"last\", v2=True)\n",
    "        self.loss_function = nn.BCEWithLogitsLoss()\n",
    "        self.train_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, node_attributes, edge_index):\n",
    "        return self.model(node_attributes, edge_index)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_pred = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        y_true = batch.interface_label.float().view(-1, 1)\n",
    "        loss = self.loss_function(y_pred, y_true)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        self.train_step_outputs.append((y_pred.detach().cpu(), y_true.detach().cpu())) # SAVE OUTPUTS\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_pred = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        y_true = batch.interface_label.float().view(-1, 1)\n",
    "        loss = self.loss_function(y_pred, y_true)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        self.validation_step_outputs.append((y_pred.detach().cpu(), y_true.detach().cpu())) # SAVE OUTPUTS\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(params=self.model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(log_every_n_steps=1, max_epochs=10, accelerator='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We add the TensorBoard logger to our Trainer and train the model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = InterfaceModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"gat\")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Every new run you train will be added to the logger so you can keep track of the improvements made over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "PyTorch Lightning has a number of [built-in callbacks](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html) which are used to perform actions at various points during training. For example, the `ModelCheckpoint` callback saves the model after each epoch, and the `EarlyStopping` callback stops training if the validation loss has not improved for a certain number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = InterfaceModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "trainer = lightning.Trainer(\n",
    "    max_epochs=50,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=2), # stop training if validation loss does not improve for 2 epochs\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\", save_top_k=1)], # save the best model based on validation loss\n",
    "    accelerator=\"cpu\",\n",
    "\n",
    ")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can also add custom callbacks to log and track things that we are interested in, such as the precision-recall curve or the ROC-AUC curve. \n",
    "\n",
    "Here's a function to calculate such curves and return the images and AUC values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics_and_curves(metric_type, y_pred, y_true, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate metrics and curves for a given metric type\n",
    "    ROC: Receiver Operating Characteristic curve, metric = Area under the curve\n",
    "    PR: Precision-Recall curve, metric = Area under the curve (Average precision)\n",
    "    CM: Confusion Matrix, metric = F1 score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metric_type : str\n",
    "        One of \"ROC\", \"PR\"\n",
    "    y_pred : torch.Tensor\n",
    "        Predicted labels\n",
    "    y_true : torch.Tensor\n",
    "        True labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metric_value : float\n",
    "        Value of the metric\n",
    "    metric_disp : matplotlib.figure.Figure\n",
    "        Figure of the curve/matrix\n",
    "    \"\"\"\n",
    "    y_true = y_true.cpu().detach().numpy()\n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    if metric_type == \"ROC\":\n",
    "        # Receiver Operating Characteristic Curve\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        roc_disp = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "        return roc_auc, roc_disp.figure_\n",
    "    elif metric_type == \"PR\":\n",
    "        # Precision-Recall Curve\n",
    "        precision, recall, _ = metrics.precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "        pr_disp = metrics.PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=pr_auc).plot()\n",
    "        return pr_auc, pr_disp.figure_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To add these to the logger, we can use the in-built functions of the Callback class to get the images at the end of each train/validation epoch and send them to the logger. Don't forget to clear the `output` variables at the end of each epoch to initialize them for the next epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogMetrics(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Log metrics and curves for validation and training\n",
    "\n",
    "    Scalars: ROC/val_AUC, ROC/train_AUC, PR/val_AUC, PR/train_AUC\n",
    "    Images: ROC/val, ROC/train, PR/val, PR/train\n",
    "    \"\"\"\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x[0] for x in pl_module.train_step_outputs], dim=0)\n",
    "        labels = torch.cat([x[1] for x in pl_module.train_step_outputs], dim=0)\n",
    "        for metric in [\"ROC\", \"PR\"]:\n",
    "            metric_auc, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/train_AUC\", metric_auc)\n",
    "            trainer.logger.experiment.add_figure(f\"{metric}/train\", metric_disp, global_step=trainer.global_step)\n",
    "        pl_module.train_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x[0] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        labels = torch.cat([x[1] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        for metric in [\"ROC\", \"PR\"]:\n",
    "            metric_auc, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/val_AUC\", metric_auc)\n",
    "            trainer.logger.experiment.add_figure(f\"{metric}/val\", metric_disp, global_step=trainer.global_step)\n",
    "        pl_module.validation_step_outputs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"gat\")\n",
    "model = InterfaceModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "trainer = lightning.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\"),\n",
    "               LogMetrics()],\n",
    "    accelerator=\"cpu\",\n",
    ")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Moving things to scripts and config files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```sh\n",
    "src/\n",
    "    __init__.py\n",
    "    dataloader.py\n",
    "        load_graph\n",
    "        ProteinDataset\n",
    "        ProteinGraphDataModule\n",
    "    models.py\n",
    "        InterfaceModel\n",
    "        InterfaceModule\n",
    "    callbacks.py\n",
    "        get_metrics_and_curves\n",
    "        LogMetrics\n",
    "train.py\n",
    "config.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In `config.yaml`:\n",
    "\n",
    "```yaml\n",
    "seed_everything: true\n",
    "model:\n",
    "  class_path: src.models.InterfaceModule\n",
    "  init_args:\n",
    "    in_channels: 20\n",
    "    num_layers: 2\n",
    "    hidden_channels: 32\n",
    "    heads: 2\n",
    "    out_channels: 1\n",
    "    dropout: 0.01\n",
    "    jk: last\n",
    "    v2: true\n",
    "data:\n",
    "  class_path: src.dataloader.ProteinGraphDataModule\n",
    "  init_args:\n",
    "    root: ./\n",
    "    columns:\n",
    "      - chain_id\n",
    "      - coords\n",
    "      - edge_index\n",
    "      - kind\n",
    "      - node_id\n",
    "      - residue_number\n",
    "      - meiler\n",
    "      - amino_acid_one_hot\n",
    "      - interface_label\n",
    "    batch_size: 32\n",
    "    num_workers: 4\n",
    "optimizer:\n",
    "  class_path: torch.optim.Adam\n",
    "  init_args:\n",
    "    lr: 0.001\n",
    "    weight_decay: 0.0001\n",
    "trainer:\n",
    "  logger:\n",
    "    - class_path: lightning.pytorch.loggers.TensorBoardLogger\n",
    "      init_args:\n",
    "        save_dir: lightning_logs\n",
    "        name: interface\n",
    "        log_graph: true\n",
    "  enable_checkpointing: true\n",
    "  callbacks:\n",
    "    - class_path: lightning.pytorch.callbacks.EarlyStopping\n",
    "      init_args:\n",
    "        patience: 5\n",
    "        monitor: val_loss\n",
    "        mode: min\n",
    "    - class_path: lightning.pytorch.callbacks.ModelCheckpoint\n",
    "      init_args:\n",
    "        save_top_k: 3\n",
    "        monitor: val_loss\n",
    "        mode: min\n",
    "        filename: \"{epoch:02d}-{val_loss:.2f}\"\n",
    "    - class_path: src.callbacks.LogMetrics\n",
    "  enable_progress_bar: true\n",
    "  max_epochs: -1\n",
    "  log_every_n_steps: 1\n",
    "  accelerator: cpu\n",
    "  strategy: auto\n",
    "  precision: 32\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "And in `train.py`:\n",
    "\n",
    "```python\n",
    "from lightning.pytorch.cli import LightningCLI\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Run with python main.py fit -c config.yaml\n",
    "    Or in an sbatch script with srun python main.py fit -c config.yaml\n",
    "    \"\"\"\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    cli = LightningCLI(save_config_kwargs={\"overwrite\": True})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric-learning",
   "language": "python",
   "name": "geometric-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
