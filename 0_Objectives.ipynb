{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Geometric Deep Learning for Protein Structure Data with PyTorch Lightning\n",
    "\n",
    "## Schedule\n",
    "- `10:00 - 10:15`: Introduction\n",
    "- `10:15 - 11:00`: [Notebook 1 - Proteins as Graphs]()\n",
    "- `11:00 - 11:30`: _Break_\n",
    "- `11:30 - 12:30`: [Notebook 2 - Graph Datasets and DataLoaders]()\n",
    "- `12:30 - 13:30`: _Lunch_\n",
    "- `13:30 - 13:45`: Introduction to geometric deep learning\n",
    "- `13:45 - 15:00`: [Notebook 3 - Geometric Deep Learning]()\n",
    "- `15:00 - 15:30`: _Break_\n",
    "- `15:30 - 16:30`: [Notebook 4 - Training and Tracking]()\n",
    "- `16:30 - 17:00`: Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Background knowledge\n",
    "\n",
    "- Protein structures\n",
    "- Deep learning\n",
    "- Graph neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Why graphs?\n",
    "- **Graphs** are a natural way to represent **interactions** between entities where the task at hand is affected both by local neighboring connections and global graph topology.\n",
    "\n",
    "- **Proteins** are made up of amino acids that are connected by chemical bonds, and **contributions from \"neighboring\" atoms can affect the properties of a given atom** to drive protein-protein binding, protein folding, and other biological processes that make up the protein's function.\n",
    "\n",
    "- When analyzing protein-protein binding, aspects such as residue-residue interactions, residue-solvent interactions, and conformational changes contribute to the entropic and enthalpic factors that drive the binding process.\n",
    "-\n",
    "- These interactions can be represented as a graph, where nodes represent atoms or amino acids and edges represent interactions between them.\n",
    "\n",
    "<div style=\"text-align: center; margin-right: 0; margin-left: auto; margin-right: auto;\">\n",
    "    <img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fpj.2014.33/MediaObjects/41428_2014_Article_BFpj201433_Fig1_HTML.jpg?as=webp\" style=\"width: 300px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Why deep learning?\n",
    "- Deep learning methods can produce data-driven features from the input representation (**feature extraction / feature learning**), useful in learning from complex, high-dimensional data for tasks where the exact features and their relationships are not known.\n",
    "\n",
    "![https://www.youtube.com/watch?v=LeeUzusWz5g](https://i0.wp.com/semiengineering.com/wp-content/uploads/2018/01/MLvsDL.png?resize=733%2C405&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- Different deep learning architectures can cope with different **unstructured data representations** (i.e not arranged as vectors of features) such as text sequences, speech signals, images and graphs.\n",
    "\n",
    "![](https://sebastianraschka.com/images/blog/2022/deep-learning-for-tabular-data/unstructured-structured.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Why geometric deep learning?\n",
    "- **Geometric deep learning** is a subfield of deep learning that focuses on learning from data that is represented as graphs or manifolds.\n",
    "\n",
    "![](https://i.ytimg.com/vi/LeeUzusWz5g/maxresdefault.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- It is particularly useful for learning from data that has a **non-Euclidean structure** such as social networks, 3D shapes, and molecule/protein structures.\n",
    "- These models can preserve both **local geometric relations** (e.g., the immediate connections between nodes in a graph or neighboring residues) and **global topological features** (e.g., the overall shape or structure of a protein), which are crucial for understanding the underlying properties of the data.\n",
    "- Many geometric data types, like graphs representing protein interactions, are **sparse** in nature. Geometric deep learning models can efficiently handle such sparsity, learning significant insights from limited interactions, which is often challenging for traditional models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "Develop a code-base for exploring, training and evaluating graph deep learning models using protein structures as input for a residue-level prediction task.\n",
    "- Learn how to featurize protein structures as graphs using [Graphein]()\n",
    "- Understand the data loading and processing pipeline for graph datasets using [PyTorch Geometric]()\n",
    "- Learn how to implement graph neural networks using [PyTorch Geometric]()\n",
    "- Understand the typical deep learning training and evaluation loops using [PyTorch Lightning]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Task and Dataset\n",
    "\n",
    "- **Given an input protein chain, predict for each residue whether or not it belongs to a protein-protein interface.**\n",
    "- The dataset (in `dataset.txt`) is a subset of the [MaSIF-site dataset](https://www.nature.com/articles/s41592-019-0666-6). \n",
    "- Each line is a PDB ID and a chain. We'll use these to extract residues at the interface with other chains and label them as positive examples. All other residues are negative examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Tips\n",
    "\n",
    "- Use the `??` operator to get the documentation of a function or class in Jupyter.\n",
    "- Play around with different parameters for the functions and classes to understand their behavior.\n",
    "- Many of the classes involved in deep learning are \"abstract classes\" that provide a blueprint for other classes to inherit from. These are of the form `class MyClass(ABC):`. Abstract classes often have methods that need to be implemented by the inheriting class. In practice, this just means that there are a set of functions (which have a fixed name and fixed input arguments) that you need to implement in your class, and you can find out what these are by looking at the documentation or source code of the abstract class. Apart from this, you can add any other methods or attributes to your class as you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Notebooks\n",
    "1. Data Preparation\n",
    "    - Constructing graphs from protein structures (Notebook 1_1)\n",
    "    - Exploring pytorch geometric graphs, constructing dataset and data module (Notebook 1_2)\n",
    "    - Load and batch data for training (Notebook 1_2)\n",
    "2. Model Development\n",
    "    - Explore off-the-shelf graph-based models (Notebook 2_1)\n",
    "    - Add custom layers and losses (Notebook 2_1)\n",
    "    - Implement training and validation (Notebook 2_1 & 2_2)\n",
    "3. Model Evaluation\n",
    "    - Log, visualise and track model performance (Notebook 2_2)\n",
    "    - Save and load trained models and checkpoints \n",
    "    - Make and save predictions\n",
    "    - Constructing configuration files and run compare models with different parameters (Notebook 2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric-learning",
   "language": "python",
   "name": "geometric-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
