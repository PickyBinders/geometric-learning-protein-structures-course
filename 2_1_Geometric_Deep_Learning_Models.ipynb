{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With proteins loaded as graphs, the next step is to build some deep learning models to learn on these graphs. There are a number of full-fledged models as well as building block layers for complex archtiectures implemented in the `torch-geometric` library:\n",
    "\n",
    "[torch_geometric.nn](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html) has a variety of graph layers that can be used to build custom GNN architectures. These include:\n",
    "- Convolution layers: These define how the message passing step is accomplished across edges in the graph. `GCNConv` is a simple example of a graph convolution layer, while `GATConv` is a more complex example with attention mechanisms.\n",
    "- Aggregation Operators: These define how messages are aggregated at each node. \n",
    "- Pooling layers: These define how nodes are aggregated into a single node.\n",
    "\n",
    "![](https://www.aritrasen.com/wp-content/uploads/2022/11/msg_1.jpg)\n",
    "![](https://www.researchgate.net/profile/Lavender-Jiang-2/publication/343441194/figure/fig4/AS:921001206509568@1596595207558/Graph-pooling-and-graph-aggregation-Graph-pooling-left-accepts-a-graph-signal-and.ppm)\n",
    "\n",
    "\n",
    "[torch_geometric.nn.models](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models) has more complex model architectures with a variety of of these layers already defined and combined inside.\n",
    "\n",
    "The [PyGModelHubMixin](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.model_hub.PyGModelHubMixin) class can be used to load pre-trained models or other model architectures from the [HuggingFace Model Hub](https://huggingface.co/models?pipeline_tag=graph-ml&sort=trending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import nn as graph_nn\n",
    "from torch import nn\n",
    "from src import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load our datamodule and get a train batch to test out these layers and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "example_train_batch = next(iter(train_loader))\n",
    "example_train_protein = datamodule.train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch essentially combines all the graphs of the individual proteins into a bigger batch graph, with an additional `batch` attribute that specifies which protein each node belongs to. Since there are no edges between the different proteins, training on this batch graph is equivalent to training on the individual graphs separately, since no information flows between the different proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 574], node_id=[231], chain_id=[231], residue_number=[231], coords=[231, 3], amino_acid_one_hot=[231, 20], meiler=[231, 7], kind=[287], num_nodes=231, x=[231, 27], pos=[231, 3], y=[231])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_train_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 3950], node_id=[8], chain_id=[8], residue_number=[1583], coords=[1583, 3], amino_acid_one_hot=[1583, 20], meiler=[1583, 7], kind=[8], num_nodes=1583, x=[1583, 27], pos=[1583, 3], y=[1583], batch=[1583], ptr=[9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_train_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we would define a graph convolutional layer that takes amino acid one hot embeddings as input node features along with the edge index to define the graph, and converts them to a 64-dimensional embedding via convolution operations across the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1583, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = graph_nn.GCNConv(in_channels=20, out_channels=64)\n",
    "example_output = layer(example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index)\n",
    "example_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some of the other layers in the torch_geometric.nn module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try out some of the pre-defined models in the `torch_geometric.nn.models` module, such as the `GAT` model which applies a series of `GATv2Conv` layers that uses attention mechanisms to weight the importance of different nodes in the graph when aggregating information from neighbors, followed by a Linear layer to convert the node embeddings to a 64-dimensional output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------------+----------------+----------+\n",
      "| Layer               | Input Shape           | Output Shape   | #Param   |\n",
      "|---------------------+-----------------------+----------------+----------|\n",
      "| GAT                 | [1583, 20], [2, 3950] | [1583, 64]     | 7,872    |\n",
      "| ├─(dropout)Dropout  | [1583, 32]            | [1583, 32]     | --       |\n",
      "| ├─(act)ReLU         | [1583, 32]            | [1583, 32]     | --       |\n",
      "| ├─(convs)ModuleList | --                    | --             | 5,760    |\n",
      "| │    └─(0)GATv2Conv | [1583, 20], [2, 3950] | [1583, 32]     | 1,408    |\n",
      "| │    └─(1)GATv2Conv | [1583, 32], [2, 3950] | [1583, 32]     | 2,176    |\n",
      "| │    └─(2)GATv2Conv | [1583, 32], [2, 3950] | [1583, 32]     | 2,176    |\n",
      "| ├─(norms)ModuleList | --                    | --             | --       |\n",
      "| │    └─(0)Identity  | [1583, 32]            | [1583, 32]     | --       |\n",
      "| │    └─(1)Identity  | [1583, 32]            | [1583, 32]     | --       |\n",
      "| │    └─(2)Identity  | [1583, 32]            | [1583, 32]     | --       |\n",
      "| ├─(lin)Linear       | [1583, 32]            | [1583, 64]     | 2,112    |\n",
      "+---------------------+-----------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "model = graph_nn.GAT(in_channels=20,\n",
    "               hidden_channels=32,\n",
    "               num_layers=3,\n",
    "               heads=2,\n",
    "               out_channels=64,\n",
    "               dropout=0.01,\n",
    "               jk=\"last\", \n",
    "               v2=True)\n",
    "print(graph_nn.summary(model, example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the `GraphUnet` model which implements a U-Net architecture for graphs, with a series of graph convolutional layers followed by pooling layers to downsample the graph, and then a series of graph convolutional layers followed by upsampling layers to upsample the graph back to the original size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scicore/home/schwede/durair0000/mambaforge/envs/leuven/lib/python3.8/site-packages/torch_geometric/utils/sparse.py:268: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  adj = torch.sparse_csr_tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+---------------------------------------+---------------------------------------------------+----------+\n",
      "| Layer                            | Input Shape                           | Output Shape                                      | #Param   |\n",
      "|----------------------------------+---------------------------------------+---------------------------------------------------+----------|\n",
      "| GraphUNet                        | [1583, 20], [2, 3950]                 | [1583, 64]                                        | 6,016    |\n",
      "| ├─(act)ReLU                      | [1583, 32]                            | [1583, 32]                                        | --       |\n",
      "| ├─(down_convs)ModuleList         | --                                    | --                                                | 2,784    |\n",
      "| │    └─(0)GCNConv                | [1583, 20], [2, 3950], [3950]         | [1583, 32]                                        | 672      |\n",
      "| │    └─(1)GCNConv                | [792, 32], [2, 2668], [2668]          | [792, 32]                                         | 1,056    |\n",
      "| │    └─(2)GCNConv                | [198, 32], [2, 522], [522]            | [198, 32]                                         | 1,056    |\n",
      "| ├─(pools)ModuleList              | --                                    | --                                                | 64       |\n",
      "| │    └─(0)TopKPooling            | [1583, 32], [2, 9320], [9320], [1583] | [792, 32], [2, 2668], [2668], [792], [792], [792] | 32       |\n",
      "| │    │    └─(select)SelectTopK   | [1583, 32], [1583]                    |                                                   | 32       |\n",
      "| │    │    └─(connect)FilterEdges | [2, 9320], [9320], [1583]             |                                                   | --       |\n",
      "| │    └─(1)TopKPooling            | [792, 32], [2, 5014], [5014], [792]   | [198, 32], [2, 522], [522], [198], [198], [198]   | 32       |\n",
      "| │    │    └─(select)SelectTopK   | [792, 32], [792]                      |                                                   | 32       |\n",
      "| │    │    └─(connect)FilterEdges | [2, 5014], [5014], [792]              |                                                   | --       |\n",
      "| ├─(up_convs)ModuleList           | --                                    | --                                                | 3,168    |\n",
      "| │    └─(0)GCNConv                | [792, 32], [2, 2668], [2668]          | [792, 32]                                         | 1,056    |\n",
      "| │    └─(1)GCNConv                | [1583, 32], [2, 3950], [3950]         | [1583, 64]                                        | 2,112    |\n",
      "+----------------------------------+---------------------------------------+---------------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "model = graph_nn.GraphUNet(in_channels=20,\n",
    "               hidden_channels=32,\n",
    "               out_channels=64,\n",
    "               depth=2,\n",
    "               pool_ratios=[0.5, 0.25],\n",
    "               )\n",
    "print(graph_nn.summary(model, example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine layers into custom architectures. Here is an example of a simple architecture that uses a GATConv layer and a GCNConv layer with some activation functions in between, and finally a linear layer to convert the 64-dimensional node embeddings to one value per node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------------+----------------+----------+\n",
      "| Layer               | Input Shape           | Output Shape   | #Param   |\n",
      "|---------------------+-----------------------+----------------+----------|\n",
      "| Sequential          | [1583, 20], [2, 3950] | [1583, 1]      | 7,105    |\n",
      "| ├─(module_0)GATConv | [1583, 20], [2, 3950] | [1583, 64]     | 2,880    |\n",
      "| ├─(module_1)ReLU    | [1583, 64]            | [1583, 64]     | --       |\n",
      "| ├─(module_2)GCNConv | [1583, 64], [2, 3950] | [1583, 64]     | 4,160    |\n",
      "| ├─(module_3)ReLU    | [1583, 64]            | [1583, 64]     | --       |\n",
      "| ├─(module_4)Linear  | [1583, 64]            | [1583, 1]      | 65       |\n",
      "+---------------------+-----------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "model = graph_nn.Sequential('x, edge_index', [\n",
    "    (graph_nn.GATConv(in_channels=20, out_channels=64, heads=2, concat=False), 'x, edge_index -> x'),\n",
    "    nn.ReLU(inplace=True),\n",
    "    (graph_nn.GCNConv(in_channels=64, out_channels=64), 'x, edge_index -> x'),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(64, 1),\n",
    "])\n",
    "\n",
    "print(graph_nn.summary(model, example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train such models with our data for our task of interface residue prediction, we need to define a loss function that takes the output of the model (the prediction) and the target labels and computes a loss value that the optimizer can use to update the model parameters. A typical choice for binary classification tasks is the binary cross entropy loss, which is implemented in PyTorch as `torch.nn.BCEWithLogitsLoss`. This loss function takes the raw output of the model and the target labels, and applies the sigmoid function to the model output to get the predicted probabilities, and then computes the binary cross entropy loss between the predicted probabilities and the target labels, defined as\n",
    "\n",
    "$$\n",
    "\\text{loss} = -\\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
    "$$\n",
    "\n",
    "where $N$ is the number of residues, $y_i$ is the target label for residue $i$ (1 if it's an interface residue, 0 if not), and $p_i$ is the predicted probability for residue $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6386, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BCEWithLogitsLoss()(model(example_train_batch.amino_acid_one_hot.float(), example_train_batch.edge_index), example_train_batch.y.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a model that predicts interface probabilities and a loss that compared them with the true interface labels, what we now need is a training loop that will iterate over the training data in batches, compute the loss, and use an optimizer to update the model parameters based on the loss value.\n",
    "\n",
    "All of this is encapsulated within the `LightningModule` class in PyTorch Lightning.\n",
    "\n",
    "![](https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/pl-walk-lit-module.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class GATModule(L.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule wrapping a GAT model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = graph_nn.GAT(in_channels=20,\n",
    "                         hidden_channels=32,\n",
    "                         num_layers=2,\n",
    "                         heads=2,\n",
    "                         out_channels=1,\n",
    "                         dropout=0.01,\n",
    "                         jk=\"last\", v2=True)\n",
    "        self.loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, node_attributes, edge_index):\n",
    "        return self.model(node_attributes, edge_index)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.y.view(-1, 1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      return torch.optim.Adam(params=self.model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Trainer` class then combines the training loop defined in the LightningModule with the data loading functions in the LightningDataModule. We set the `max_epochs` to 5, meaning that the training loop will iterate over the entire training data 5 times, updating the model parameters with each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scicore/home/schwede/durair0000/mambaforge/envs/leuven/lib/python3.8/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scicore/home/schwede/durair0000/mambaforge/envs/leu ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/scicore/home/schwede/durair0000/mambaforge/envs/leuven/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | model         | GAT               | 3.6 K \n",
      "1 | loss_function | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "/scicore/home/schwede/durair0000/mambaforge/envs/leuven/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6483cbd8e6af4d5686f7930086b57e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "model = GATModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "trainer = L.Trainer(enable_progress_bar=True, max_epochs=5)\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this runs the training loop for 5 epochs, what we really want to do is to monitor the performance of the model on the validation data (and maybe even stop training when the performance stops improving). We'd probably like to see some metrics like accuracy, precision, recall, and F1 score, as well as the loss value and how those change over time, both on the training data and the validation data to make sure the model is learning something useful and not overfitting. All of this needs more complex logging and monitoring than what we've done so far, covered in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "- How would you change things for protein-protein input?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
