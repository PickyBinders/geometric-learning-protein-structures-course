{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch, and by extension PyTorch-Geometric, has some standardized ways of handling data and datasets. We first need to make a torch `Data` object from our graphs, with graphein's conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphein.ml import GraphFormatConvertor\n",
    "from src import dataloader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "            \"chain_id\",\n",
    "            \"coords\",\n",
    "            \"edge_index\",\n",
    "            \"kind\",\n",
    "            \"node_id\",\n",
    "            \"residue_number\",\n",
    "            \"amino_acid_one_hot\",\n",
    "            \"meiler\"\n",
    "]\n",
    "\n",
    "convertor = GraphFormatConvertor(src_format=\"nx\", dst_format=\"pyg\", columns=columns, verbose = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphein_graph, interface_labels = dataloader.load_graph(\"1A22\", \"A\", \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain what X and Y are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphein_to_torch_graph(graphein_graph, interface_labels, convertor, \n",
    "                              node_attr_columns = [\"amino_acid_one_hot\", \"meiler\"]):\n",
    "    \"\"\"\n",
    "    Converts a Graphein graph to a pytorch-geometric Data object.\n",
    "    \"\"\"\n",
    "    data = convertor(graphein_graph)\n",
    "    data_dict= data.to_dict()\n",
    "    x_data = []\n",
    "    for x in node_attr_columns:\n",
    "        if data_dict[x].ndim == 1:\n",
    "            x_data.append(torch.atleast_2d(data_dict[x]).T)\n",
    "        else:\n",
    "            x_data.append(torch.atleast_2d(data_dict[x]))\n",
    "    data.x = torch.hstack(x_data).float()\n",
    "    data.pos = data.coords.float()\n",
    "    data.y = torch.zeros(data.num_nodes)\n",
    "    for i, node_id in enumerate(data.node_id):\n",
    "        if node_id in interface_labels:\n",
    "            data.y[i] = 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric_graph = graphein_to_torch_graph(graphein_graph, interface_labels, convertor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: explore the data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `torch_geometric.data.Dataset` class is a standard way of representing a graph dataset in PyTorch. It is an abstract class that you can subclass to create your own dataset. Here's what the tyical architecture of a dataset looks like:\n",
    "\n",
    "TODO: list the methods that need to be implemented\n",
    "TODO: add code to run this for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    \"\"\"\n",
    "    torch-geometric Dataset class for loading protein files as graphs.\n",
    "    \"\"\"\n",
    "    def __init__(self, root,\n",
    "                 protein_names: list, \n",
    "                 pre_transform=None, \n",
    "                 transform=None):\n",
    "        self.protein_names = protein_names\n",
    "        super(ProteinDataset, self).__init__(root, pre_transform=pre_transform, transform=transform)\n",
    "\n",
    "    def download(self):\n",
    "        for protein_name in self.protein_names:\n",
    "            output = Path(self.raw_dir) / f'{protein_name}.pkl'\n",
    "            if not output.exists():\n",
    "                pdb_id, chain = protein_name.split(\"_\")\n",
    "                graphein_graph, interface_labels = dataloader.load_graph(pdb_id, chain)\n",
    "                with open(output, \"wb\") as f:\n",
    "                    pickle.dump((graphein_graph, interface_labels), f)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [Path(self.raw_dir) / f\"{protein_name}.pkl\" for protein_name in self.protein_names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [Path(self.processed_dir) / f\"{protein_name}.pt\" for protein_name in self.protein_names]\n",
    "\n",
    "    def process(self):\n",
    "        for protein_name in self.protein_names:\n",
    "            output = Path(self.processed_dir) / f'{protein_name}.pt'\n",
    "            if output.exists():\n",
    "                continue\n",
    "            with open(Path(self.raw_dir) / f\"{protein_name}.pkl\", \"rb\") as f:\n",
    "                graphein_graph, interface_labels = pickle.load(f)\n",
    "            torch_graph = graphein_to_torch_graph(graphein_graph, interface_labels)\n",
    "            if self.pre_transform is not None:\n",
    "                torch_graph = self.pre_transform(torch_graph)\n",
    "            torch.save(torch_graph, output)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(self.processed_file_names[idx])\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This puts together what we've been implementing for loading proteins as graphs with graphein, converting those into PyTorch-geometric Data objects and then wrapping those into a PyTorch Dataset. \n",
    "\n",
    "Graphein also has a built-in `ProteinGraphDataset` class that combines these steps. It also has some nice features like (1) the ability to load a dataset of proteins from both the PDB or AlphaFold Database directory of PDB files, (2) the ability to apply custom transformations from your bioinformatics tools of choice to the PDB files (with the `pdb_transform` argument)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "- pre-transforms and transforms\n",
    "- how to use the `ProteinGraphDataset` class to include AlphaFold models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
