{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of free and paid resources available for interactively tracking training performance of deep learning models. Here we'll use [TensorBoard](https://github.com/tensorflow/tensorboard) which is free and open-source. Another popular option with a free tier is [Weights & Biases](https://wandb.ai/site), which has some additional features and integrations. \n",
    "\n",
    "We can actually visualise TensorBoard within the notebook with some cell magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric import nn as graph_nn\n",
    "from src import dataloader\n",
    "from lightning.pytorch import callbacks\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more cell magic runs TensorBoard, tells Jupyter to run the server in the background and display it in the notebook, by looking for files in the `lightning_logs` directory. As we run training, log files will be written to this directory by default and the TensorBoard display will update automatically (refreshes every 30 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "I0301 11:04:29.874209 140622885418752 plugin.py:429] Monitor runs begin\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs/ --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the LightningModule again and this time also log the loss value on our validation set. Note that the `validation_step` function automatically runs with gradients disabled, meaning that weights are frozen and the model is in evaluation mode, so we don't need to worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModule(L.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule wrapping a GAT model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = graph_nn.GAT(in_channels=20,\n",
    "                         hidden_channels=32,\n",
    "                         num_layers=2,\n",
    "                         heads=2,\n",
    "                         out_channels=1,\n",
    "                         dropout=0.01,\n",
    "                         jk=\"last\", v2=True)\n",
    "        self.loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, node_attributes, edge_index):\n",
    "        return self.model(node_attributes, edge_index)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.y.view(-1, 1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.y.view(-1, 1))\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(params=self.model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(log_every_n_steps=1, max_epochs=10, accelerator='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the TensorBoard logger to our Trainer and train the model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A0G_B\n",
      "1A0H_D\n",
      "1A22_A\n",
      "1A2K_AB\n",
      "1A6J_B\n",
      "1A79_C\n",
      "1AA7_A\n",
      "1ACB_I\n",
      "1AIH_D\n",
      "1ARZ_C\n",
      "1AVA_C\n",
      "1AVO_K\n",
      "1AVO_L\n",
      "1AZS_AB\n",
      "1B0N_A\n",
      "1B27_A\n",
      "1B27_D\n",
      "1B35_B\n",
      "1B35_C\n",
      "1B4U_C\n",
      "1B65_D\n",
      "1B6C_B\n",
      "1B9L_D\n",
      "1B9M_A\n",
      "1B9Y_C\n",
      "1BBH_A\n",
      "1BC5_A\n",
      "1BCP_H\n",
      "1BCP_L\n",
      "1BCR_A\n",
      "1BCR_B\n",
      "1BDF_D\n",
      "1BIH_A\n",
      "1BJA_A\n",
      "1BO4_A\n",
      "1BPL_A\n",
      "1BVN_T\n",
      "1BVP_2\n",
      "1C3X_A\n",
      "1C8N_C\n",
      "1C8O_A\n",
      "1C8U_B\n",
      "1CGI_I\n",
      "1CLI_A\n",
      "1CMV_B\n",
      "1CN4_B\n",
      "1CQ3_B\n",
      "1CQI_B\n",
      "1D8H_A\n",
      "1D9E_B\n",
      "1DB2_A\n",
      "1DBQ_B\n",
      "1DHK_B\n",
      "1DJ8_B\n",
      "1DK4_A\n",
      "1DLE_A\n",
      "1DLT_A\n",
      "1DM9_B\n",
      "1DML_A\n",
      "1DNW_B\n",
      "1DPJ_A\n",
      "1DQN_A\n",
      "1DS8_L\n",
      "1DXX_C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | model         | GAT               | 3.6 K \n",
      "1 | loss_function | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A0G_B\n",
      "1A0H_D\n",
      "1A22_A\n",
      "1A2K_AB\n",
      "1A6J_B\n",
      "1A79_C\n",
      "1AA7_A\n",
      "1ACB_I\n",
      "1AIH_D\n",
      "1ARZ_C\n",
      "1AVA_C\n",
      "1AVO_K\n",
      "1AVO_L\n",
      "1AZS_AB\n",
      "1B0N_A\n",
      "1B27_A\n",
      "1B27_D\n",
      "1B35_B\n",
      "1B35_C\n",
      "1B4U_C\n",
      "1B65_D\n",
      "1B6C_B\n",
      "1B9L_D\n",
      "1B9M_A\n",
      "1B9Y_C\n",
      "1BBH_A\n",
      "1BC5_A\n",
      "1BCP_H\n",
      "1BCP_L\n",
      "1BCR_A\n",
      "1BCR_B\n",
      "1BDF_D\n",
      "1BIH_A\n",
      "1BJA_A\n",
      "1BO4_A\n",
      "1BPL_A\n",
      "1BVN_T\n",
      "1BVP_2\n",
      "1C3X_A\n",
      "1C8N_C\n",
      "1C8O_A\n",
      "1C8U_B\n",
      "1CGI_I\n",
      "1CLI_A\n",
      "1CMV_B\n",
      "1CN4_B\n",
      "1CQ3_B\n",
      "1CQI_B\n",
      "1D8H_A\n",
      "1D9E_B\n",
      "1DB2_A\n",
      "1DBQ_B\n",
      "1DHK_B\n",
      "1DJ8_B\n",
      "1DK4_A\n",
      "1DLE_A\n",
      "1DLT_A\n",
      "1DM9_B\n",
      "1DML_A\n",
      "1DNW_B\n",
      "1DPJ_A\n",
      "1DQN_A\n",
      "1DS8_L\n",
      "1DXX_C\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5466931796bd46f9908c6e1629a62eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4e4f7d2f67490c982a430f57024e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a905a6056e4e8b8e6d368f571c931e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2154abe0472040cf9a1fff7ffcbd3f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5847f79cd10e4cfea4e5fd3c237b9ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341ba5a64ff349b4bedaafd44a6ceae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb6df47acb84a10a9e22e616319a8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97aba0bfb9b43858fb2c0fbb3d4de28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf34ebddbab4402874e09e6833d272b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ac7c7e2d4d4afb8ee50070373f28ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf4fdfdc0eb43918f6310ff7e207dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3ac4acbeee4f7d89a6c9ed5c63a1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "model = GATModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"gat\")\n",
    "\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every new run you train will be added to the logger so you can keep track of the improvements made over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Lightning has a number of [built-in callbacks](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html) which are used to perform actions at various points during training. For example, the `ModelCheckpoint` callback saves the model after each epoch, and the `EarlyStopping` callback stops training if the validation loss has not improved for a certain number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory lightning_logs/gat/version_0/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | model         | GAT               | 3.6 K \n",
      "1 | loss_function | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8956ce42324021adfe639afeb4e261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed62306c278448abd20083c82b30c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f67689426c4ab78630c860d377f9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6badabb8b624c1899713ef355a4250d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d99e3e7a474bf2acffd2264c6c7b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408f6074f8e54ac1ad77c4e81b7d82ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce404c77920482fbdd461aec9d01d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x11fd4dd30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87da5dd7d80d45f4b6773e466014b458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GATModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=2), # stop training if validation loss does not improve for 2 epochs\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\", save_top_k=1)], # save the best model based on validation loss\n",
    "    accelerator=\"cpu\",\n",
    "\n",
    ")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add custom callbacks to log and track things that we are interested in, such as the precision-recall curve or the ROC-AUC curve. Here's a function to calculate such curves and return the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_and_curves(metric_type, y_pred, y_true, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate metrics and curves for a given metric type\n",
    "    ROC: Receiver Operating Characteristic curve, metric = Area under the curve\n",
    "    PR: Precision-Recall curve, metric = Area under the curve (Average precision)\n",
    "    CM: Confusion Matrix, metric = F1 score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metric_type : str\n",
    "        One of \"ROC\", \"PR\"\n",
    "    y_pred : torch.Tensor\n",
    "        Predicted labels\n",
    "    y_true : torch.Tensor\n",
    "        True labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metric_value : float\n",
    "        Value of the metric\n",
    "    metric_disp : matplotlib.figure.Figure\n",
    "        Figure of the curve/matrix\n",
    "    \"\"\"\n",
    "    y_true = y_true.cpu().detach().numpy()\n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    if metric_type == \"ROC\":\n",
    "        # Receiver Operating Characteristic Curve\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        roc_disp = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "        return roc_auc, roc_disp.figure_\n",
    "    elif metric_type == \"PR\":\n",
    "        # Precision-Recall Curve\n",
    "        precision, recall, _ = metrics.precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "        pr_disp = metrics.PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=pr_auc).plot()\n",
    "        return pr_auc, pr_disp.figure_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add these to the logger, we need to save the predictions and targets for each batch during training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModule(L.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule wrapping a GAT model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = graph_nn.GAT(in_channels=20,\n",
    "                         hidden_channels=32,\n",
    "                         num_layers=2,\n",
    "                         heads=2,\n",
    "                         out_channels=1,\n",
    "                         dropout=0.01,\n",
    "                         jk=\"last\", v2=True)\n",
    "        self.loss_function = nn.BCEWithLogitsLoss()\n",
    "        self.train_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, node_attributes, edge_index):\n",
    "        return self.model(node_attributes, edge_index)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.y.view(-1, 1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        self.train_step_outputs.append((out.detach().cpu(), batch.y)) # SAVE OUTPUTS\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.y.view(-1, 1))\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        self.validation_step_outputs.append((out.detach().cpu(), batch.y)) # SAVE OUTPUTS\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(params=self.model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the in-built function sof the Callback class to get the images at the end of each train/validation epoch and send them to the logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogMetrics(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Log metrics and curves for validation and training\n",
    "\n",
    "    Scalars: ROC/val_AUC, ROC/train_AUC, PR/val_AUC, PR/train_AUC, CM/val_F1, CM/train_F1\n",
    "    Images: ROC/val, ROC/train, PR/val, PR/train, CM/val, CM/train\n",
    "    \"\"\"\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x[0] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        labels = torch.cat([x[1] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        for metric in [\"ROC\", \"PR\"]:\n",
    "            metric_auc, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/val_AUC\", metric_auc)\n",
    "            trainer.logger.experiment.add_figure(f\"{metric}/val\", metric_disp, global_step=trainer.global_step)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x[0] for x in pl_module.train_step_outputs], dim=0)\n",
    "        labels = torch.cat([x[1] for x in pl_module.train_step_outputs], dim=0)\n",
    "        for metric in [\"ROC\", \"PR\"]:\n",
    "            metric_auc, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/train_AUC\", metric_auc)\n",
    "            trainer.logger.experiment.add_figure(f\"{metric}/train\", metric_disp, global_step=trainer.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | model         | GAT               | 3.6 K \n",
      "1 | loss_function | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31672ab24c3847ef9f46ae163cb3372e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jay/mambaforge/envs/geometric-learning/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888efa08761340db88d5cf7169bdb499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c901e132c9ca45d79bc81f28453c0353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423c12d700884d9da792b190cfda6a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2739e3f9b0474fe6b80585dd7a584f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6fec55531a4ca485ca1d02bf36a24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e79b80fabc4a5eafadf3252c5a8fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ac9d49fe4e445bb17421c307335722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c507012afe410ab0222fabfca5a168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f318b856c5304fa5b439b2330898bc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d858d677272d415ea30ed3aa5b4ca18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4a6be0a9b24118b03dc5aeab61f57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca0a614427a4a74a9fb9368596698b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c6eb8f1f504b5b8cba734fd5f7b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bb2848a0d84429a0111fe82a6610e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e9dd2d32bf44e9aaa06f11e2f56010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"gat\")\n",
    "model = GATModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\"),\n",
    "               LogMetrics()],\n",
    "    accelerator=\"cpu\",\n",
    ")\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "- Check out wandb\n",
    "- Learning rate schedulers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leuven_course_env",
   "language": "python",
   "name": "leuven_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
