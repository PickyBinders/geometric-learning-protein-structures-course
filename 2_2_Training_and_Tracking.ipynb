{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Intro to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dataloader, models\n",
    "import pytorch_lightning as L\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GATModule(\n",
    "    in_channels=20,\n",
    "    num_layers=3,\n",
    "    hidden_channels=128,\n",
    "    num_heads=4,\n",
    "    out_channels=1,\n",
    "    dropout=0.01,\n",
    "    jk='cat',\n",
    "  )\n",
    "\n",
    "datamodule = dataloader.ProteinDataModule(\n",
    "root=\"./data\",\n",
    "dataset_file=\"dataset.txt\",\n",
    "batch_size=32,\n",
    "num_workers=4,\n",
    ")\n",
    "\n",
    "logger = L.loggers.TensorBoardLogger('logs', name='gat', log_graph=True) #changed (TODO: mention log_graph linked to example_input_array)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    enable_progress_bar=True,\n",
    "    max_epochs=5,\n",
    "\n",
    "    logger=logger, #changed\n",
    "    log_every_n_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Built-in callbacks](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    enable_progress_bar=True,\n",
    "    max_epochs=5,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\")],\n",
    "\n",
    ")\n",
    "trainer.fit(model=model, datamodule=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pnd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_metrics_and_curves(metric_type, y_pred, y_true, invert=False, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate metrics and curves for a given metric type\n",
    "    ROC: Receiver Operating Characteristic curve, metric = Area under the curve\n",
    "    PR: Precision-Recall curve, metric = Area under the curve (Average precision)\n",
    "    CM: Confusion Matrix, metric = F1 score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metric_type : str\n",
    "        One of \"ROC\", \"PR\", \"CM\"\n",
    "    y_pred : torch.Tensor\n",
    "        Predicted labels\n",
    "    y_true : torch.Tensor\n",
    "        True labels\n",
    "    invert : bool\n",
    "        If True, do 1 - y_pred, use if y_pred is distance instead of probability\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metric_value : float\n",
    "        Value of the metric\n",
    "    metric_disp : matplotlib.figure.Figure\n",
    "        Figure of the curve/matrix\n",
    "    \"\"\"\n",
    "    if invert:\n",
    "        y_pred = 1 - y_pred\n",
    "    y_true = y_true.cpu().detach().numpy()\n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    if metric_type == \"ROC\":\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        roc_disp = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "        return roc_auc, roc_disp.figure_\n",
    "    elif metric_type == \"PR\":\n",
    "        # Precision-Recall Curve\n",
    "        precision, recall, _ = metrics.precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "        pr_disp = metrics.PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=pr_auc).plot()\n",
    "        return pr_auc, pr_disp.figure_\n",
    "    elif metric_type == \"CM\":\n",
    "        confusion_matrix = metrics.confusion_matrix(y_true, y_pred > threshold)\n",
    "        df_cm = pnd.DataFrame(confusion_matrix)\n",
    "        plt.figure(figsize = (10,7))\n",
    "        cm_disp = sns.heatmap(df_cm, annot=True, cmap='Blues').get_figure()\n",
    "        plt.close(cm_disp)\n",
    "        f1 = metrics.f1_score(y_true, y_pred > threshold)\n",
    "        return f1, cm_disp\n",
    "\n",
    "\n",
    "\n",
    "class LogMetrics(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Log metrics and curves for validation and training\n",
    "\n",
    "    Scalars: ROC/val_AUC, ROC/train_AUC, PR/val_AUC, PR/train_AUC, CM/val_F1, CM/train_F1\n",
    "    Images: ROC/val, ROC/train, PR/val, PR/train, CM/val, CM/train\n",
    "    \"\"\"\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x['out'] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        labels = torch.cat([x['y'] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        for metric, value in zip([\"ROC\", \"PR\", \"CM\"], [\"AUC\", \"AUC\", \"F1\"]):\n",
    "            metric_value, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/val_{value}\", metric_value)\n",
    "            if trainer.current_epoch % 10 == 0:\n",
    "                trainer.logger.experiment.add_figure(f\"{metric}/val\", metric_disp, global_step=trainer.global_step)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x['out'] for x in pl_module.train_step_outputs], dim=0)\n",
    "        labels = torch.cat([x['y'] for x in pl_module.train_step_outputs], dim=0)\n",
    "        for metric, value in zip([\"ROC\", \"PR\", \"CM\"], [\"AUC\", \"AUC\", \"F1\"]):\n",
    "            metric_value, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/train_{value}\", metric_value)\n",
    "            if trainer.current_epoch % 10 == 0:\n",
    "                trainer.logger.experiment.add_figure(f\"{metric}/train\", metric_disp, global_step=trainer.global_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    enable_progress_bar=True,\n",
    "    max_epochs=5,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\"),\n",
    "               LogMetrics()],\n",
    ")\n",
    "trainer.fit(model=model, datamodule=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "- Check out wandb\n",
    "- Learning rate schedulers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
