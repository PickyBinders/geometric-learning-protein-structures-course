{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of free and paid resources available for interactively tracking training performance of deep learning models. Here we'll use [TensorBoard](https://github.com/tensorflow/tensorboard) which is free and open-source. Another popular option with a free tier is [Weights & Biases](https://wandb.ai/site), which has some additional features and integrations. \n",
    "\n",
    "We can actually visualise TensorBoard within the notebook with some cell magic. This tells Jupyter to run the TensorBoard server in the background and display it in the notebook, by looking for files in the `lightning_logs` directory. As we run training, log files will be written to this directory by default and the TensorBoard display will update automatically (refreshes every 30 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the LightningModule again and this time also log the loss value on our validation set. Note that the `validation_step` function automatically runs with gradients disabled, meaning that weights are frozen and the model is in evaluation mode, so we don't need to worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric import nn as graph_nn\n",
    "from src import dataloader\n",
    "\n",
    "class GATModule(L.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule wrapping a GAT model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = graph_nn.GAT(in_channels=20,\n",
    "                         hidden_channels=32,\n",
    "                         num_layers=2,\n",
    "                         heads=2,\n",
    "                         out_channels=1,\n",
    "                         dropout=0.01,\n",
    "                         jk=\"last\", v2=True)\n",
    "        self.loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, node_attributes, edge_index):\n",
    "        return self.model(node_attributes, edge_index)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.y.view(-1, 1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        out = self(batch.amino_acid_one_hot.float(), batch.edge_index)\n",
    "        loss = self.loss_function(out, batch.y.view(-1, 1))\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, sync_dist=True,\n",
    "                 batch_size=batch.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(params=self.model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "/scicore/home/schwede/durair0000/mambaforge/envs/leuven/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /scicore/home/schwede/durair0000/projects/leuven_course/lightning_logs/version_44909931/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | model         | GAT               | 3.6 K \n",
      "1 | loss_function | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scicore/home/schwede/durair0000/mambaforge/envs/leuven/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78b826012b7434bb07318f6d1b97ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "model = GATModule()\n",
    "datamodule = dataloader.ProteinGraphDataModule(\"./test_data\", \"dataset.txt\")\n",
    "trainer = L.Trainer(max_epochs=2)\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b2688ef75d35c09d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b2688ef75d35c09d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs/ --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Built-in callbacks](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    enable_progress_bar=True,\n",
    "    max_epochs=5,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\")],\n",
    "\n",
    ")\n",
    "trainer.fit(model=model, datamodule=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pnd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_metrics_and_curves(metric_type, y_pred, y_true, invert=False, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate metrics and curves for a given metric type\n",
    "    ROC: Receiver Operating Characteristic curve, metric = Area under the curve\n",
    "    PR: Precision-Recall curve, metric = Area under the curve (Average precision)\n",
    "    CM: Confusion Matrix, metric = F1 score\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metric_type : str\n",
    "        One of \"ROC\", \"PR\", \"CM\"\n",
    "    y_pred : torch.Tensor\n",
    "        Predicted labels\n",
    "    y_true : torch.Tensor\n",
    "        True labels\n",
    "    invert : bool\n",
    "        If True, do 1 - y_pred, use if y_pred is distance instead of probability\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metric_value : float\n",
    "        Value of the metric\n",
    "    metric_disp : matplotlib.figure.Figure\n",
    "        Figure of the curve/matrix\n",
    "    \"\"\"\n",
    "    if invert:\n",
    "        y_pred = 1 - y_pred\n",
    "    y_true = y_true.cpu().detach().numpy()\n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    if metric_type == \"ROC\":\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        roc_disp = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "        return roc_auc, roc_disp.figure_\n",
    "    elif metric_type == \"PR\":\n",
    "        # Precision-Recall Curve\n",
    "        precision, recall, _ = metrics.precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "        pr_disp = metrics.PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=pr_auc).plot()\n",
    "        return pr_auc, pr_disp.figure_\n",
    "    elif metric_type == \"CM\":\n",
    "        confusion_matrix = metrics.confusion_matrix(y_true, y_pred > threshold)\n",
    "        df_cm = pnd.DataFrame(confusion_matrix)\n",
    "        plt.figure(figsize = (10,7))\n",
    "        cm_disp = sns.heatmap(df_cm, annot=True, cmap='Blues').get_figure()\n",
    "        plt.close(cm_disp)\n",
    "        f1 = metrics.f1_score(y_true, y_pred > threshold)\n",
    "        return f1, cm_disp\n",
    "\n",
    "\n",
    "\n",
    "class LogMetrics(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Log metrics and curves for validation and training\n",
    "\n",
    "    Scalars: ROC/val_AUC, ROC/train_AUC, PR/val_AUC, PR/train_AUC, CM/val_F1, CM/train_F1\n",
    "    Images: ROC/val, ROC/train, PR/val, PR/train, CM/val, CM/train\n",
    "    \"\"\"\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x['out'] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        labels = torch.cat([x['y'] for x in pl_module.validation_step_outputs], dim=0)\n",
    "        for metric, value in zip([\"ROC\", \"PR\", \"CM\"], [\"AUC\", \"AUC\", \"F1\"]):\n",
    "            metric_value, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/val_{value}\", metric_value)\n",
    "            if trainer.current_epoch % 10 == 0:\n",
    "                trainer.logger.experiment.add_figure(f\"{metric}/val\", metric_disp, global_step=trainer.global_step)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        outputs = torch.cat([x['out'] for x in pl_module.train_step_outputs], dim=0)\n",
    "        labels = torch.cat([x['y'] for x in pl_module.train_step_outputs], dim=0)\n",
    "        for metric, value in zip([\"ROC\", \"PR\", \"CM\"], [\"AUC\", \"AUC\", \"F1\"]):\n",
    "            metric_value, metric_disp = get_metrics_and_curves(metric, outputs, labels)\n",
    "            pl_module.log(f\"{metric}/train_{value}\", metric_value)\n",
    "            if trainer.current_epoch % 10 == 0:\n",
    "                trainer.logger.experiment.add_figure(f\"{metric}/train\", metric_disp, global_step=trainer.global_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    enable_progress_bar=True,\n",
    "    max_epochs=5,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "\n",
    "    callbacks=[callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "               callbacks.ModelCheckpoint(monitor=\"val_loss\"),\n",
    "               LogMetrics()],\n",
    ")\n",
    "trainer.fit(model=model, datamodule=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "- Check out wandb\n",
    "- Learning rate schedulers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leuven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
